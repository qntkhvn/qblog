[
["index.html", "DATA 229 - FINAL PROJECT 1 About The Project", " DATA 229 - FINAL PROJECT Quang Nguyen Spring 2018 1 About The Project This is the Final Project Portfolio for my Introduction to Data Science course (Data 229) at Wittenberg University. Data 229 is the first ever Data Science course offered at Wittenberg University and is taught by Professor Douglas Andrews. My portfolio consists of analysis of six datasets, in two different parts: Part I: Three datasets selected by Professor Andrews (who also wrote the introduction to all 3 datasets): KenKen Solar Dolphins Part II: Three datasets chosen by me: Goals Grades Tennis2017 "],
["part-i-kenken.html", "2 Part I - KenKen 2.1 Introduction 2.2 Analysis", " 2 Part I - KenKen 2.1 Introduction 2.1.1 Topic For a year and a half, Obed Lewis and I (D.Andrews) collected data on how long it took us to solve KenKen puzzles. At the time, we had access only to the two daily puzzles in the print version of the New York Times, which we could get only on weekdays while school was in session. 2.1.2 Data In the KenKen subfolder are such data, in a tidy, “narrow” format. Each case is a combination of Puzzle, Solver, and Size. Below are the variables: Puzzle: This variable is somewhat misleadingly named. It’s really not an ID for a particular puzzle. Rather, it’s a chronological, sequential ID for the day in our study period on which a pair of puzzles appeared, from 1 = Mon 31 Jan 2011, to 213 = Wed 2 May 2012 Day, Year, Month, Date: the day of the week, year, month, and calendar date on which the puzzles appeared Semester: 1 = Spring 2011, 2 = Fall 2011, 3 = Spring 2012 Solver: Doug or Obed Size: 4x4 or 6x6 (grid of cells) Minutes, Seconds: These two combined give the total solution time, e.g., 3:12 is recorded as Minutes = 3 and Seconds = 12. Notes: reasons why we didn’t get a chance to do the day’s puzzles during the study period 2.2 Analysis First, the following packages must be loaded before analyzing this dataset. library(tidyverse) library(readxl) library(mosaic) library(knitr) Next, I read in the data file and named it “KenKen” KenKen &lt;- read_excel(&quot;~/Data229/Project/KenKen/KenKen Solution Times for Obed and Doug.xlsx&quot;) 2.2.1 Solution Time Since the solution time was recorded as 2 variables (Minutes and Seconds), it might be a better idea to state the time in terms of seconds. KenKen &lt;- KenKen %&gt;% mutate(Time = Minutes*60 + Seconds) KenKen %&gt;% ggplot(size = 0.05) + geom_histogram(mapping = aes(Time), na.rm = TRUE, color = &quot;black&quot;, fill = &quot;grey&quot;) FALSE `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. The distribution of solution times is strongly skewed to the right, so it might be easier to analyze by transforming the Time variable using a log transformation. A new variable called log(Time) was created. KenKen &lt;- KenKen %&gt;% mutate(logTime = log(Time)) ggplot(data = KenKen, size = 0.05) + geom_histogram(mapping = aes(logTime), na.rm = TRUE, color = &quot;black&quot;, fill = &quot;grey&quot;) FALSE `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. kable(favstats(~ logTime, data = KenKen)) min Q1 median Q3 max mean sd n missing 2.484907 3.332205 4.369448 5.095279 7.944847 4.330372 1.090571 852 74 The distribution of solution log(Time) looks kind of normalish. The mean solution log(Time) is about 4.33 log seconds. The solution log(Time) varies from 2.485 log sec to 7.945 log sec. 2.2.2 Factors that affect the solution time 2.2.2.1 Puzzle’s Size KenKen %&gt;% filter(!is.na(Size), !is.na(Time)) %&gt;% ggplot(mapping = aes(x = Size, y = logTime, color = Size)) + geom_boxplot() Looking at the boxplot, it is easier to recognize that overall, the mean log(time) to complete puzzles of size 4x4 is smaller than 6x6. So the size of the puzzle does have an impact on the solution time. In particular, the smaller the size is, the shorter time the solvers used. 2.2.2.2 Puzzle’s Solver KenKen %&gt;% filter(!is.na(Solver), !is.na(Time)) %&gt;% ggplot(mapping = aes(x = Solver, y = logTime, color = Solver)) + geom_boxplot() Doug is the faster solver, since his mean log(time) is slightly less than Obed’s. But overall, the range of the two solvers’ log(time) are about the same. Obed’s solution log(Time) has 2 outliers. 2.2.2.3 Solving Day KenKen %&gt;% filter(!is.na(Solver), !is.na(Time)) %&gt;% ggplot(mapping = aes(x = Day, y = logTime, color = Day)) + geom_boxplot() As the week goes by, the puzzle seems to get harder and harder, as the mean log(Time) increases throughout the week. Friday and Thursday’s mean log(Time) are the two highest among the 5 weekdays - about 6 log(Seconds). This means on those 2 days, it took longer to solve Ken Ken. On the other hand, the mean log(Time) on Monday and Tuesday are lowest, meaning that puzzles were easier and took a shorter time to solve. 2.2.2.3.1 Conclusion: To sum up, 2 out of the 3 factors listed above have some impact on the solution time: Size of the puzzle seems to have the biggest impact, as the mean log(Time) of 4x4 is way less than 6x6. The difference between the 2 means is very big, in particular the mean log(Time) for 6x6 is as high as 4x4’s max log(Time). Day of the week also affects the solution time. On the first 2 days (Monday and Tuesday), the mean log(Time) are the least. Puzzle on those 2 days might be easier than the others and the solving times are quicker. In contrast, the last 2 weekdays (Thursday and Friday) have the greatest mean log(Time). Puzzles were tougher to solve on those 2 days. Puzzle’s solver looks to be the only factor that have a tiny impact/ or even doesn’t affect the solution time. The 2 mean log(Time) are about the same (though Doug was a little bit faster than Obed). Everything else (range, IQR,…) also looks to be equal. 2.2.3 Did the solvers get faster? KenKen %&gt;% filter(!is.na(Month), !is.na(logTime)) %&gt;% ggplot(mapping = aes(x = as.factor(Month), y = logTime)) + geom_boxplot() + facet_grid(.~ Year) Overall, we can see that the solution time doesn’t have any particular trend. Over the course of the 3-semester period between 2011 and 2012, the mean log(Time) just keeps going up, and then down, and then up and down again, sort of like the graph of the sine curve. There were some months that the solution log(Time) is low, for example August 2011 and March 2012, meaning that those months are the fastest solving months. There were also months such as February 2011 and September 2011 where the solution times are the slowest. "],
["part-i-solar.html", "3 Part I - Solar 3.1 Introduction 3.2 Data Wrangling 3.3 Data Exploring", " 3 Part I - Solar 3.1 Introduction 3.1.1 Topic I (D.Andrews) have a small home solar array. Its electrical energy generation not only offsets my own consumption, but the surplus essentially pays off my other fees from the electrical company each month. The inverter (which converts the DC current produced by the photoelectric panels to the AC current that we actually use) records how much power is generated at any given time, and it reports this to the manufacturer’s data repository via my home wifi. The manufacturer’s system then automatically sends me daily and weekly reports on the system’s energy performance. 3.1.2 Data In the Solar subfolder are all my weekly reports from 2017. Each weekly report has 8 lines - a header and data for each day of that week - so the cases are days. The report format changed early in the year. Here are the variables for the first few reports: date time of the report energy generated by this inverter, in Watt-hours (Wh) total energy generated by all inverters on the array ratio of the energy generated (in Wh) to the maximum power rating (in W) of the array The time of the report is always 00:00:00, so that’s worthless. I have only one inverter, so the total energy is always identical to the energy of my lone inverter. That ratio will always be perfectly proportional to the energy generated, so it’s redundant info, too. Here are the variables in the remaining reports: date energy generated by this inverter, in kiloWatt-hours (kWh) ratio of energy generated to maximum power rating (in kWh/kW) total energy generated that day by all my inverters 3.2 Data Wrangling Before making any data analysis, the following packages must be loaded: library(tidyverse) library(mosaic) library(knitr) 3.2.1 Early Reports I wanted to combine the early reports into 1 table, since there are 3 early reports files and I didn’t want to import each one of those, do some wrangling and duplicate my work again. So to combine the files, I did the following: First, I set the working directory, using the setwd() function. Then, the list.files() function was used to get a list of all files in the directory. I also used getwd() to get the working directory. Since I only wanted the early reports, I used grepl() to look for all files that begins with “W” - which are the early reports’ files. After that, I utilized the lapply() function to apply read.csv() to all values of EarlyFiles. I also set header = FALSE, stringsAsFactors = FALSE (to make sure character values are imported as characters, not factors) and skipped the first row of each file (the row that contains the variable names). The result of each read.csv() was stored in a list, so I used do.call() and rbind to turn it into one data table. I called this output table “Solar1” setwd(&quot;~/Data229/Project/Solar/&quot;) EarlyFiles &lt;- list.files(getwd()) EarlyFiles &lt;- EarlyFiles[grepl(&quot;^W&quot;, EarlyFiles)] Solar1 &lt;- lapply(EarlyFiles, read.csv, header = FALSE, stringsAsFactors = FALSE, skip = 1) Solar1 &lt;- do.call(rbind, Solar1) I renamed the first and second columns as “Date” and “Energy_Wh” (since the energy is measured in Wh in these first files). I then used select() to select the first 2 columns because I only need those 2. colnames(Solar1)[1] &lt;- &quot;Date&quot; colnames(Solar1)[2] &lt;- &quot;Energy_Wh&quot; Solar1 &lt;- select(Solar1, Date, Energy_Wh) Now let’s take a quick look at the data table we get by combining the early reports. kable(Solar1 %&gt;% head()) Date Energy_Wh 02.01.2017 00:00:00 2017.9711 03.01.2017 00:00:00 1051.9311 04.01.2017 00:00:00 16025.5489 05.01.2017 00:00:00 726.2458 06.01.2017 00:00:00 10947.3014 07.01.2017 00:00:00 16800.0856 3.2.2 Remaining Reports To combine the remaining reports, I repeated the same process I used to combine the early reports. The only changes I made was that I looked for filenames that starts with “PV” (which are the remaining files) and skipped the first 2 rows of these files. The output table is named “Solar2” setwd(&quot;~/Data229/Project/Solar&quot;) RemainingFiles &lt;- list.files(getwd()) RemainingFiles &lt;- RemainingFiles[grepl(&quot;^PV&quot;, RemainingFiles)] Solar2 &lt;- lapply(RemainingFiles, read.csv, header = FALSE, stringsAsFactors = FALSE, skip = 2) Solar2 &lt;- do.call(rbind, Solar2) colnames(Solar2)[1] &lt;- &quot;Date&quot; colnames(Solar2)[2] &lt;- &quot;Energy&quot; Solar2 &lt;- select(Solar2, Date, Energy) 3.2.3 Joining Tables Now, in order to make the some data analysis, I need to figure out how to join the tables together. The final data table should have the following variables: Month Day Energy The following wrangling techniques were performed on both tables: Separating the date For table 1, since energy in the remaining files is measured in kWh, I wanted to change the unit of energy in these early files into the exact same unit, using this conversion: 1 kWh = 1000 Wh. Creating a new variable called “FakeYear” (we need a year for the date variable) Solar1 &lt;- Solar1 %&gt;% separate(Date, into = c(&quot;Day&quot;, &quot;Month&quot;, &quot;Year&quot;,&quot;Time1&quot;, &quot;Time2&quot;, &quot;Time3&quot;)) %&gt;% mutate(Energy = Energy_Wh/1000, FakeYear = 1000) %&gt;% unite(FakeDate, FakeYear, Month, Day, sep = &quot;-&quot;) %&gt;% mutate(FakeDate = as.Date(FakeDate), Energy = as.double(Energy)) %&gt;% select(FakeDate, Year, Energy) Solar2 &lt;- Solar2 %&gt;% separate(Date, into = c(&quot;Day&quot;, &quot;Month&quot;, &quot;Year&quot;)) %&gt;% mutate(FakeYear = 1000) %&gt;% unite(FakeDate, FakeYear, Month, Day, sep = &quot;-&quot;) %&gt;% mutate(FakeDate = as.Date(FakeDate), Energy = as.double(Energy)) After that, it’s time to join the 2 tables. I named the final table “Solar2017”. Solar2017 &lt;- full_join(Solar1, Solar2, by = &quot;FakeDate&quot;) Solar2017 &lt;- select(Solar2017, FakeDate, Energy.x, Energy.y) The output table is “wide”. To turn it into a “narrow” table, I gathered the energy into one column. colnames(Solar2017)[1] &lt;- &quot;Date&quot; Solar2017 &lt;- gather(Solar2017, Energy.x, Energy.y, key = &quot;EnergyXY&quot;, value = &quot;Energy&quot;) Solar2017 &lt;- Solar2017 %&gt;% filter(!is.na(Energy)) %&gt;% select(-EnergyXY) %&gt;% arrange((Date)) %&gt;% separate(Date, into = c(&quot;Year&quot;, &quot;Month&quot;, &quot;Day&quot;)) %&gt;% select(-Year) After a few other wrangling steps, I finally got the data table that I need. Here is the first few rows of the final table: kable(Solar2017 %&gt;% head()) Month Day Energy 01 02 2.0179711 01 03 1.0519311 01 04 16.0255489 01 05 0.7262458 01 06 10.9473014 01 07 16.8000856 3.3 Data Exploring 3.3.1 2017 Energy Solar2017 %&gt;% ggplot(mapping = aes(Energy)) + geom_histogram(bins = 20, color = &quot;black&quot;, fill = &quot;grey&quot;) kable(favstats(~ Energy, data = Solar2017)) min Q1 median Q3 max mean sd n missing 0 5.405 12.89 17.275 23.9 11.54916 6.625288 364 0 The distribution of 2017 Energy is somewhat skewed to the left. The average enery the array generated was 11.55 kWh. The maximum energy generated on one day was 23.8; whereas the minimum is 0, which means the array was down during those day. 3.3.2 Monthly Energy Solar2017 %&gt;% ggplot(mapping = aes(x = Month, y = Energy)) + geom_boxplot() The distribution of energy looks normalish. The 3 summer months (June, July and August) have the most amount of energy generated, which is no surprised since summer is the “sunniest” time of the year. The highest enery generated day is actually in May. On the other hand, January and December are when the energy generated the least, because those are 2 winter months and we can hardly see the sun during wintertime. 3.3.3 No Energy Generated kable(Solar2017 %&gt;% filter(Energy == 0) %&gt;% count(Month)) Month n 10 2 11 3 12 8 Solar2017 %&gt;% filter(Energy == 0) %&gt;% ggplot(mapping = aes(Month)) + geom_bar() The array was down 2 times in October, 3 times in November and 8 times in December, so it was down for a total of 13 days in 2017. "],
["part-i-dolphins.html", "4 Part I - Dolphins 4.1 Introduction 4.2 Data Wrangling 4.3 Data Exploring", " 4 Part I - Dolphins 4.1 Introduction 4.1.1 Topic Wittenberg’s Marine Science major Heddie Samuelson has graciously provided data from her research on dolphins. Dolphins often swim together in “pods”, and Heddie wants to know how the pod size varies, and how pod size might be related to other variables. 4.1.2 Data In the Dolphins subfolder are two files…. In the Sightings file, the cases are particular sightings of dolphin pods in a particular area on the north Atlantic coast of the US. Variables include the following: Date and Time of the sighting Location of the sighting, specified by Latitude and Longitude Estimated pod size (in the variable labeled “#”), i.e., the number of dolphins in the pod Species and Common Name of the variety of dolphins sighted Note that there are 11 sheets - one for each year from 2006 through 2016. There are three sheets in the SeaTemps file. Ignore the “AVERAGE SST” sheet (which includes monthly averages and a graph that you will probably do anyway) and “Sheet2” (which duplicates one year’s data in Sheet1). In Sheet1 there are four similar variables for each of the 11 years: date sea surface temperature in Fahrenheit, for that date sea surface temperature in Celsius, for that date average sea surface temperature in Celsius, for that month (typically listed on the first day of the month) Note that there are lots of missing data and blank columns, and that all 11 years of sea temps are on this one sheet. Note also that there are different numbers of rows for the different years. 4.2 Data Wrangling Before making my analysis, I loaded the following packages: library(tidyverse) library(readxl) library(mosaic) library(knitr) library(maps) Since the 2006 sheet is slightly different from the other sheets (it has 2 extra rows below the data), I read in this sheet separately. Sight06 &lt;- read_excel(&quot;~/Data229/Project/Dolphins/Sightings.xlsx&quot;, sheet = &quot;2006&quot;, n_max = 62) Sight06 &lt;- Sight06 %&gt;% select(Date, Time, Latitude, Longitude, &quot;#&quot;) %&gt;% mutate(Date = as.Date(Date)) Then, a function to read in the sheets from 2007 to 2016 was created. Beside from importing the plain datasets, I also did some wrangling to make it look better. Sightings &lt;- function(sheetNum){ SightTable &lt;- read_excel(&quot;~/Data229/Project/Dolphins/Sightings.xlsx&quot;, sheet = sheetNum) SightTable &lt;- SightTable %&gt;% select(Date, Time, Latitude, Longitude, &quot;#&quot;) %&gt;% mutate(Date = as.Date(Date))} After the function was defined, it’s now time to get the data. Sight07 &lt;- Sightings(2) Sight08 &lt;- Sightings(3) Sight09 &lt;- Sightings(4) Sight10 &lt;- Sightings(5) Sight11 &lt;- Sightings(6) Sight12 &lt;- Sightings(7) Sight13 &lt;- Sightings(8) Sight14 &lt;- Sightings(9) Sight15 &lt;- Sightings(10) Sight16 &lt;- Sightings(11) My goal is to have an output table with 5 variables Date, Time, Latitude, Longitude and podSize. I used 10 full_join()’s to join 11 tables to get my table. I also renamed column 5 “podSize”. Sights &lt;- Sight06 %&gt;% full_join(Sight07, by = c(&quot;Date&quot;, &quot;Time&quot;, &quot;Latitude&quot;, &quot;Longitude&quot;, &quot;#&quot;)) %&gt;% full_join(Sight08, by = c(&quot;Date&quot;, &quot;Time&quot;, &quot;Latitude&quot;, &quot;Longitude&quot;, &quot;#&quot;)) %&gt;% full_join(Sight09, by = c(&quot;Date&quot;, &quot;Time&quot;, &quot;Latitude&quot;, &quot;Longitude&quot;, &quot;#&quot;)) %&gt;% full_join(Sight10, by = c(&quot;Date&quot;, &quot;Time&quot;, &quot;Latitude&quot;, &quot;Longitude&quot;, &quot;#&quot;)) %&gt;% full_join(Sight11, by = c(&quot;Date&quot;, &quot;Time&quot;, &quot;Latitude&quot;, &quot;Longitude&quot;, &quot;#&quot;)) %&gt;% full_join(Sight12, by = c(&quot;Date&quot;, &quot;Time&quot;, &quot;Latitude&quot;, &quot;Longitude&quot;, &quot;#&quot;)) %&gt;% full_join(Sight13, by = c(&quot;Date&quot;, &quot;Time&quot;, &quot;Latitude&quot;, &quot;Longitude&quot;, &quot;#&quot;)) %&gt;% full_join(Sight14, by = c(&quot;Date&quot;, &quot;Time&quot;, &quot;Latitude&quot;, &quot;Longitude&quot;, &quot;#&quot;)) %&gt;% full_join(Sight15, by = c(&quot;Date&quot;, &quot;Time&quot;, &quot;Latitude&quot;, &quot;Longitude&quot;, &quot;#&quot;)) %&gt;% full_join(Sight16, by = c(&quot;Date&quot;, &quot;Time&quot;, &quot;Latitude&quot;, &quot;Longitude&quot;, &quot;#&quot;)) colnames(Sights)[5] &lt;- &quot;podSize&quot; It might actually be a better idea to split the Day column into 3 columns Year, Month and Day; since I’m going to find out how the pod size distribution varies by time of year and across the years. SightsYMD &lt;- Sights %&gt;% separate(Date, into = c(&quot;Year&quot;, &quot;Month&quot;, &quot;Day&quot;)) Now I finally have the table that I wanted. Let’s take a quick look at its first few rows. kable(SightsYMD %&gt;% head()) Year Month Day Time Latitude Longitude podSize 2006 07 25 1519 42.70759 -70.50612 50 2006 07 26 1645 42.85215 -70.32297 70 2006 07 26 1632 42.84765 -70.32412 40 2006 07 29 1431 42.73842 -70.52207 20 2006 07 29 1445 42.74283 -70.51724 10 2006 08 02 1615 42.90334 -70.34932 30 4.3 Data Exploring 4.3.1 Pod Size Now it’s time to analyze. First, I wanted to check out the pod size distribution. SightsYMD %&gt;% ggplot(mapping = aes(podSize)) + geom_histogram(bins = 40, color = &quot;black&quot;, fill = &quot;grey&quot;) The shape of the distribution of pod size is skewed to the right, so I decided to use a log transformation and therefore model the log(podSize). SightsYMD %&gt;% ggplot(mapping = aes(log(podSize))) + geom_histogram(bins = 25, color = &quot;black&quot;, fill = &quot;grey&quot;) Sure enough! The log(podSize) distribution looks normalish At this time, I’d like to check out factors that affect pod size 4.3.1.1 Time of the Year Below is a log(podSize) vs Month boxplot: SightsYMD %&gt;% ggplot(mapping = aes(x= Month, y = log(podSize))) + geom_boxplot() The first thing I noticed was all the data was recorded in 8 months from May to November. The mean log(podSize) is about the same in those months. The log(podSize) are highest in August, September and October, meaning that the number of dolphins in the pod is biggest during those month. On the other hand, May is the month that has the lowest mean log(podSize), and this indicates the estimated size is smallest in May. 4.3.1.2 Year (2006-2016) Next, let’s find out how does pod size vary across the years. SightsYMD %&gt;% ggplot(mapping = aes(x = Year, y = log(podSize))) + geom_boxplot() Overall, the mean log(podSize) doesn’t seem to be very different throughout the years. So year seems to have a tiny or even no impact on pod size. Some years (2009, 2016,…) the number of dolphins is slightly bigger than the others - as their mean log(podSize) are the highest (about 4). On the other hand, the lowest mean log(podSize) is about 3 (in 2013), and this is not that much smaller than the other ones. 4.3.1.3 Time of the Day In order to see how does pod size vary by time of the day, I compared the log(podSize) of 4 different periods: Morning (before 11:00) Noonish (11:00 - 14:00) Afternoon (14:00 - 17:00) Evening (after 17:00) Here are the summary statistics for each one of the period I just mentioned: Morning &lt;- SightsYMD %&gt;% filter(Time &lt;= 1100) kable(favstats(~ log(podSize), data = Morning)) min Q1 median Q3 max mean sd n missing 0 2.484907 3.401197 4.317488 6.214608 3.369225 1.174626 152 0 Noonish &lt;- SightsYMD %&gt;% filter(Time &gt; 1100 &amp; Time &lt;= 1400) kable(favstats(~ log(podSize), data = Noonish)) min Q1 median Q3 max mean sd n missing 0 2.70805 3.68888 4.60517 5.703782 3.488528 1.214849 255 0 Afternoon &lt;- SightsYMD %&gt;% filter(Time &gt; 1400 &amp; Time &lt;= 1700) kable(favstats(~ log(podSize), data = Afternoon)) min Q1 median Q3 max mean sd n missing 0 2.70805 3.401197 4.248495 6.907755 3.425035 1.069065 472 1 Evening &lt;- SightsYMD %&gt;% filter(Time &gt; 1700) kable(favstats(~ log(podSize), data = Noonish)) min Q1 median Q3 max mean sd n missing 0 2.70805 3.68888 4.60517 5.703782 3.488528 1.214849 255 0 Overall, mean and median log(podSize) are about the same for all 4 periods of the day (around 3.5). So we can say that time of the day doesn’t affect pod size at all. The highest log(podSize) is 6.9 - in the afternoon. 4.3.1.4 Location USA &lt;- map_data(&quot;usa&quot;) States &lt;- map_data(&quot;state&quot;) colnames(SightsYMD)[5] &lt;- &quot;lat&quot; colnames(SightsYMD)[6] &lt;- &quot;long&quot; This map illustrates the location of the sighting. USA %&gt;% ggplot(mapping = aes(x = long, y = lat)) + geom_polygon(mapping = aes(group = group), color = &quot;brown&quot;, fill = &quot;tan&quot;) + geom_point(data = SightsYMD, mapping = aes(x = long, y = lat, size = podSize)) + coord_fixed(xlim = c(-71, -70), ylim = c(42.1, 43.2)) All the location of sighting is in the Atlantic coast of the US. It seems like locations that have longitude from -70.6 to -70.25 and latitude from 42.75 to 43 are where pod size is the largest. 4.3.2 Sea Surface Temperature The next thing I did was to look at the sea surface temperature. First, I loaded the SeaTemps data file. SeaTemps &lt;- read_excel(&quot;~/Data229/Project/Dolphins/SeaTemps.xlsx&quot;, sheet = &quot;Sheet2&quot;) SeaTemps &lt;- SeaTemps[,1:2] SeaTemps &lt;- SeaTemps %&gt;% filter(`SST (deg F)` != &quot;N/A&quot;) %&gt;% mutate(Temperature = as.double(`SST (deg F)`), Date = as.Date(Date)) %&gt;% select(-`SST (deg F)`) Now let’s look at the average temperature in each month. Here are the numerical and visual summaries of average sea surface temperature. kable(AvgTemp &lt;- SeaTemps %&gt;% separate(Date, into = c(&quot;Year&quot;, &quot;Month&quot;, &quot;Day&quot;)) %&gt;% group_by(Month) %&gt;% summarise(AvgTemp = mean(Temperature))) Month AvgTemp 05 50.51983 06 58.76095 07 65.20261 08 66.83306 09 63.39961 10 57.59091 AvgTemp %&gt;% ggplot(mapping = aes(x = Month, y = AvgTemp, group = &quot;&quot;)) + geom_line(color = &quot;red&quot;, size = 2) + geom_point(color = &quot;blue&quot;, size = 5) The average sea surface temperature is highest in August, at about 67 degree F. July, August and September are the 3 months that sea surface is warmer, since they are have mean temperature over 63 degree. In contrast, the surface is cooler in May, June and October (all under 60 degree); and May is the coldest month with average temperature of slightly above 50 F. 4.3.3 Pod Size vs Temperature Sights &lt;- Sights %&gt;% select(Date, podSize) %&gt;% mutate(Date = as.Date(Date)) PodTemp &lt;- full_join(Sights, SeaTemps, by = &quot;Date&quot;) PodTemp %&gt;% ggplot(mapping = aes(y = Temperature, x = log(podSize))) + geom_point() + stat_smooth(method = &quot;lm&quot;, se = FALSE) lm(Temperature ~ log(podSize), data = PodTemp) Call: lm(formula = Temperature ~ log(podSize), data = PodTemp) Coefficients: (Intercept) log(podSize) 65.0016 0.2285 The plot above reveals a positive but weak and linearish relationshoip between log(podSize) and Temperature. This means larger log(podSize) is associated with warmer sea surface temperature. The regression equation is Temp^ = 0.23*log(podSize) + 65. It has a slope of 0.23, which indicates every factor of e in pod size is associated with an increase of 0.23 degree F in temperature. "],
["part-ii-goals.html", "5 Part II - Goals 5.1 Introduction 5.2 Analysis", " 5 Part II - Goals 5.1 Introduction 5.1.1 Topic Cristiano Ronaldo Cristiano Ronaldo is arguably one of the top football (soccer) player of all time. Ronaldo is famous for his speed, dribbling skills, and most importantly, his goal scoring ability. As a guy who has been following soccer for more than 15 years, I have witnessed so many goals that Ronaldo has scored throughout his career, from stunning direct free kicks to crucial game-winning shots. Ronaldo used to be my favorite player, due to the fact that he spent 6 seasons from 2003 to 2009 with my favorite ball squad - Manchester United. Then he left MU and joined Real Madrid, where he has elevated his game to a whole new level and established himself as one of the top footballers in the world. Because of all the information I just mentioned, I decided to choose a dataset about Ronaldo’s goals and provide some analyses on it. 5.1.2 Data The data was collected from Transfermarkt.com. Notice that all the goals in this dataset are all Ronaldo’s goal at the Club level (i.e. none of them are his International goals for his home nation - Portugal). The dataset does not have any names for the variables, so I will assign the variable’s names. Each of Ronaldo’s goals is represented by the following variables (which I’ll assign, of course!): Season: A total of 16 seasons from 2002-03 to 2017-18 Competition: 11 different leagues and cups that Ronaldo has scored in Competition_Type: Whether a competion is a Domestic League, Domestic Cup, European Cup or International Cup Club: The 3 clubs that Ronaldo has played for Opponent: Clubs that Ronaldo has scored against Opponents_Country: The opposing squad’s “nationality” Treated_as: For the most part, this is basically where the goals were in the back of the net (Home/Away). But in some cases, for example, UEFA Champions League Final, the game was played at a neutral field, a team will be treated as the “Home” team and got to wear their Home uniform. Final_Score: The result of the matches Minute: At what point of the match did a goal took place? Score_at_this_point: The game score after a goal Type_of_goal: Whether a goal is a header, left/right-footed shot, tap-in, penalty or direct free kick 5.2 Analysis I started off by loading the packages that I’ll need to analyze the dataset. library(tidyverse) library(mosaic) library(readxl) library(maps) library(knitr) Next, the dataset was loaded from my personal drive. Goals &lt;- read_excel(&quot;~/Data229/Project/Goals/CR7 Goals.xlsx&quot;, col_names = FALSE) Like I mentioned above, the following names were being assigned to the variables of this dataset: colnames(Goals) &lt;- c(&quot;Season&quot;,&quot;Competition&quot;,&quot;Competition_Type&quot;,&quot;Club&quot;,&quot;Opponent&quot;,&quot;Opponents_Country&quot;,&quot;Treated_as&quot;,&quot;Final_Score&quot;,&quot;Minute&quot;,&quot;Score_at_this_point&quot;,&quot;Type_of_Goal&quot;) There were also a number of missing cells in the inital dataset. This is because when Ronaldo scored multiple goals in one match, they just recorded the goals’ minute, the score after a goal and the type of goal. So the fill() function was used to complete this dataset. Goals &lt;- Goals %&gt;% fill(Season, Competition, Competition_Type, Club, Opponent, Opponents_Country, Treated_as, Final_Score, Minute, Score_at_this_point, Type_of_Goal) 5.2.1 Club Goals The first figure that I chose to analyze was Ronaldo’s club goals. Below are the visual and numerical summaries for Ronaldo’s goals for his 3 teams: Goals %&gt;% group_by(Club) %&gt;% summarise(Club_Goals = n()) %&gt;% kable() Club Club_Goals Manchester United 118 Real Madrid 449 Sporting CP 5 Goals %&gt;% group_by(Club) %&gt;% summarise(Club_Goals = n()) %&gt;% ggplot(mapping = aes(x = &quot;&quot;, y = Club_Goals, fill = Club)) + geom_bar(stat = &quot;identity&quot;) + coord_polar(&quot;y&quot;, start = 0) + scale_fill_brewer(palette =&quot;Blues&quot;) + theme_minimal() + ggtitle(&quot;Ronaldo&#39;s Club Goals&quot;) + xlab(&quot;&quot;) + ylab(&quot;&quot;) Ronaldo has scored 449 goals for Real Madrid, which is the highest among the 3 clubs that he has played for. He also had 118 goals for Manchester United, and his career Sporting CP goals is only 5. 5.2.2 Competition Goals Below are the visual and numerical summaries for Ronaldo’s goals in leagues and cups. I actually created a table called “CompetitionsGoals” since I’ll use this later on. kable(Competition_Goals &lt;- Goals %&gt;% group_by(Competition) %&gt;% summarise(Competition_Goals = n())) Competition Competition_Goals Copa del Rey 22 English Football League Cup 3 English Premier League 84 FA Cup 14 FIFA Club World Cup 7 La Liga 310 Primeira Liga 3 Spanish Supercopa 4 Taca de Portugal 2 UEFA Champions League 121 UEFA Supercup 2 Competition_Goals %&gt;% ggplot(mapping = aes(x = &quot;&quot;, y = Competition_Goals, fill = Competition)) + geom_bar(stat = &quot;identity&quot;) + coord_polar(&quot;y&quot;, start = 0) + scale_fill_brewer(palette =&quot;Set3&quot;) + theme_minimal() + ggtitle(&quot;Ronaldo&#39;s Competition Goals&quot;) + xlab(&quot;&quot;) + ylab(&quot;&quot;) Ronaldo has scored the most goals in the La Liga (310). His next 2 highest scoring compeitions are UEFA Champions League (121) and English Premier League (84). On the other hand, Ronaldo’s number of goals in smaller competitions like UEFA Supercup, Taca de Portugal, Primeira Liga,… are very small, primarily due to him playing a tiny amount of games in those leagues/cups (which I’ll get to in just a bit) 5.2.3 Goals vs Appearances Is the a connection between Ronaldo’s goals and the number of competition matches he has participated in? We’ll soon find out! The table below illustrates the total number of games Ronaldo has played in 11 different leagues/cups (The data was collected from Wikipedia): kable(Appearances &lt;- tribble( ~Competition, ~Matches, &quot;English Premier League&quot;, 196, &quot;La Liga&quot;, 291, &quot;Primeira Liga&quot;, 25, &quot;Taca de Portugal&quot;, 3, &quot;Copa del Rey&quot;, 30, &quot;FA Cup&quot;, 26, &quot;English Football League Cup&quot;, 12, &quot;UEFA Supercup&quot;, 2, &quot;Spanish Supercopa&quot;, 7, &quot;FIFA Club World Cup&quot;, 8, &quot;UEFA Champions League&quot;, 158)) Competition Matches English Premier League 196 La Liga 291 Primeira Liga 25 Taca de Portugal 3 Copa del Rey 30 FA Cup 26 English Football League Cup 12 UEFA Supercup 2 Spanish Supercopa 7 FIFA Club World Cup 8 UEFA Champions League 158 Now, let’s make a graph to find out the relationship between goals and games played. But before the plot is made, I joined the 2 tables Competition_Goals and Appearances to get a new table called “Goals_n_Matches” Here’s a look at that table: kable(Goals_n_Matches &lt;- full_join(Competition_Goals, Appearances, by = &quot;Competition&quot;)) Competition Competition_Goals Matches Copa del Rey 22 30 English Football League Cup 3 12 English Premier League 84 196 FA Cup 14 26 FIFA Club World Cup 7 8 La Liga 310 291 Primeira Liga 3 25 Spanish Supercopa 4 7 Taca de Portugal 2 3 UEFA Champions League 121 158 UEFA Supercup 2 2 Now I can use the table I just created to make my graph. Goals_n_Matches %&gt;% ggplot(mapping = aes(x = Matches, y = Competition_Goals)) + geom_point(mapping = aes(color = Competition)) + stat_smooth(method = &quot;lm&quot;, se = FALSE) The plot reveals a strong, linear and positive relationship between Competition goals and matches. The overall trend is the more games Ronaldo plays in a competition, the more goals he scores. lm(Competition_Goals ~ Matches, data = Goals_n_Matches) Call: lm(formula = Competition_Goals ~ Matches, data = Goals_n_Matches) Coefficients: (Intercept) Matches -9.4125 0.8912 The regression equation is CompGoals^ = 0.8912*Matches - 9.41 The slope of this equation is 0.8912, which indicates that every extra match is associated with an increase of 0.89 in goals. (If he plays 100 matches, his total goals will increase by about 89) 5.2.4 Goals per Season Goals %&gt;% group_by(Season, Club) %&gt;% summarise(Total_Goals = n()) %&gt;% ggplot(mapping = aes(x = as.factor(Season), y = Total_Goals)) + geom_point(mapping = aes(size = Total_Goals, color = Club)) + ggtitle(&quot;Ronaldo&#39;s Club Goals per Season&quot;) + xlab(&quot;Season&quot;) + ylab(&quot;Goals&quot;) Based on the graph, Ronaldo’s scoring has improved throughout his career. During the 6 years stretch from 2010 to 2015, Ronaldo scored 40 or more goals in every single season. His highest scoring season was 2014-15 where he netted more than 60 goals. The number of goals during Ronaldo first 4 years season is not high, simply because he was still a “baby” back then and did not have plenty of playing time. 5.2.5 Multiple Goals Ronaldo is a great scorer, and we’ve seen him scored multiple goals in a match so many times. This table shows how many matches Ronaldo has put the ball in the opponent’s net more than 1 time. I used the following soccer lingo to illustrate the amount of goals scored: Brace = 2 goals Hat-trick = 3 goals Poker = 4 goals Glut = 5 goals kable(MultipleGoals &lt;- Goals %&gt;% group_by(Season, Competition, Competition_Type, Club, Opponent, Opponents_Country, Treated_as, Final_Score) %&gt;% summarise(Scored = n()) %&gt;% filter(Scored &gt; 1) %&gt;% group_by(Scored) %&gt;% summarise(Total = n()) %&gt;% spread(key = Scored, value = Total) %&gt;% rename(Brace = &quot;2&quot;,&quot;Hat-trick&quot; = &quot;3&quot;, Poker = &quot;4&quot;, Glut = &quot;5&quot;) %&gt;% gather(Brace, &#39;Hat-trick&#39;, Poker, Glut, key = Scored, value = Total)) Scored Total Brace 104 Hat-trick 37 Poker 6 Glut 2 Ronaldo has played against many opponents from different nations in his career. This table is named MultipleGoals and it shows several different countries and how many matches Ronaldo has scored more than 1 goal against opponents from those countries. For example, if Country = France and HowManyTimes = 4, this means CR7 has scored multiple goals in 4 matches against French teams. (This is not the same as the number of goals he has had in France!) kable(MultipleGoals &lt;- Goals %&gt;% group_by(Season, Competition, Competition_Type, Club, Opponent, Opponents_Country, Treated_as, Final_Score) %&gt;% summarise(Scored = n()) %&gt;% filter(Scored &gt; 1) %&gt;% group_by(Opponents_Country) %&gt;% rename(Country = Opponents_Country) %&gt;% summarise(HowManyTimes = n())) Country HowManyTimes Cyprus 3 Denmark 1 England 24 France 4 Germany 8 Italy 4 Japan 1 Netherlands 2 Portugal 1 Russia 1 Spain 92 Sweden 2 Switzerland 1 Turkey 2 Ukraine 3 The table below shows all the countries in the MultipleGoals table and their latitude (lat) and longtitude (long). I chose that lat and long of the capital city or biggest city of each nation to represent the whole nation. kable(Places &lt;- tribble( ~Country, ~lat, ~long, &quot;Cyprus&quot;, 35.2, 33.4, &quot;Denmark&quot;, 55.7, 12.6, &quot;England&quot;, 51.5, -0.1, &quot;France&quot;, 48.9, 2.3, &quot;Germany&quot;, 52.5, 13.4, &quot;Italy&quot;, 41.9, 12.5, &quot;Netherlands&quot;, 52.4, 4.9, &quot;Portugal&quot;, 38.7, -9.1, &quot;Russia&quot;, 55.8, 37.6, &quot;Spain&quot;, 40.4, -3.7, &quot;Sweden&quot;, 59.3, 18.1, &quot;Switzerland&quot;, 47.6, 7.6, &quot;Turkey&quot;, 41.0, 29.0, &quot;Ukraine&quot;, 50.5, 30.5, &quot;Japan&quot;, 35.7, 139.8)) Country lat long Cyprus 35.2 33.4 Denmark 55.7 12.6 England 51.5 -0.1 France 48.9 2.3 Germany 52.5 13.4 Italy 41.9 12.5 Netherlands 52.4 4.9 Portugal 38.7 -9.1 Russia 55.8 37.6 Spain 40.4 -3.7 Sweden 59.3 18.1 Switzerland 47.6 7.6 Turkey 41.0 29.0 Ukraine 50.5 30.5 Japan 35.7 139.8 Next, I used a full_join to join 2 tables Places and MultipleGoals and I named my new table “Opponents” kable(Opponents &lt;- full_join(Places, MultipleGoals, by = &quot;Country&quot;)) Country lat long HowManyTimes Cyprus 35.2 33.4 3 Denmark 55.7 12.6 1 England 51.5 -0.1 24 France 48.9 2.3 4 Germany 52.5 13.4 8 Italy 41.9 12.5 4 Netherlands 52.4 4.9 2 Portugal 38.7 -9.1 1 Russia 55.8 37.6 1 Spain 40.4 -3.7 92 Sweden 59.3 18.1 2 Switzerland 47.6 7.6 1 Turkey 41.0 29.0 2 Ukraine 50.5 30.5 3 Japan 35.7 139.8 1 World &lt;- map_data(&quot;world&quot;) This map indicates the countries that Ronaldo has scored multiple goals against teams from those countries. World %&gt;% ggplot(mapping = aes(x = long, y = lat)) + geom_polygon(mapping = aes(group = group), fill = &quot;lightgrey&quot;) + geom_point(data = Opponents, mapping = aes(x = long, y = lat, fill = &quot;blue&quot;, size = HowManyTimes, color = Country)) + coord_fixed(ratio = 1.8, xlim = c(-5,138), ylim = c(33, 75)) + theme(legend.position = &quot;none&quot;) The bigger the point is, the more times Ronaldo has scored more than 1 goal in a match against teams from the country represented by that point. Spain (the very big blue point) and England (the big orange point) are the 2 nations where their teams often conceeded more than 1 Ronaldo’s goal in a game. All but 1 country is European - the only 1 that is not is Japan (the lonely dot to the right of the map). 5.2.6 Types of Goal Goals %&gt;% group_by(Type_of_Goal) %&gt;% summarise(count = n()) %&gt;% kable() Type_of_Goal count Direct free kick 45 Header 91 Left-footed shot 92 Penalty 96 Right-footed shot 234 Tap-in 14 Goals %&gt;% ggplot(mapping = aes(Type_of_Goal)) + geom_bar(fill = c(7:12)) Overall, we can see that Ronaldo has had more right-footed shots than any other types of goal, which is not surprised because he is right-footed. He is also an all-around scorer. The number of goals as a header, a left-footed shot and a penalty are about the same. Ronaldo has also turned about 50 direct free kicks into goals and the number tap-in’s is the least among the 6 types of goal. "],
["part-ii-grades.html", "6 Part II - Grades 6.1 Introduction 6.2 Analysis", " 6 Part II - Grades 6.1 Introduction 6.1.1 Topic Grades seems to be a lame topic, but wouldn’t it be fun to look at all of your grades from middle school to high school? And that’s what this analysis is all about. I’m going to take a look back at my grades from 6th to 10th grade (my time back in Vietnam). I think this is also a good opportunity for me to look at what I have accomplished and how I have improved as a learner during those years. 6.1.2 Data It is easy for me to collect the data because I brought my middle school and high school transcipt with me. I created 5 separate excel files. They are my 6th, 7th, 8th, 9th and 10th Grade’s grades (my “Vietnamese grades”). Each one the 5 dataset is in the wide format and has 3 variables: Subject: The classes that I took in those years My Term I grade My Term II grade The grades are my semester average grades for each one of the subject and in Vietnam, we use a 10-point grading scale. 6.2 Analysis As always, I loaded the following R packages before making my data analysis library(tidyverse) library(readxl) library(knitr) library(mosaic) 6.2.1 Data Wrangling Since I wanted to import 5 of my Vietnamese grades’ files, it’s a good idea not to repeat the same importing process and so I write a function to capture this process. I named the function “Grades” Grades &lt;- function(grade){ GradesFile &lt;- paste(&quot;~/Data229/Project/Grades/Q_Grades_VN_&quot;, grade, &quot;thGrade.xlsx&quot; ,sep = &quot;&quot;) GradesTable &lt;- read_excel(GradesFile) } Now after creating my function, I can just simply get the tables of my grades in 6th, 7th, 8th , 9th and 10th Grade. Grade6 &lt;- Grades(6) Grade7 &lt;- Grades(7) Grade8 &lt;- Grades(8) Grade9 &lt;- Grades(9) Grade10 &lt;- Grades(10) Ultimately, my goal is to have a table in a narrow (tall) format with 3 variables: Subject, Term and Grade. So I first used 4 full_join’s to create a table in a wide format. I also renamed the all the term columns. GradeVN &lt;- Grade6 %&gt;% full_join(Grade7, by = &quot;Subject&quot;) %&gt;% full_join(Grade8, by = &quot;Subject&quot;) %&gt;% full_join(Grade9, by = &quot;Subject&quot;) %&gt;% full_join(Grade10, by = &quot;Subject&quot;) colnames(GradeVN) &lt;- c(&quot;Subject&quot;, &quot;TermI.6&quot;, &quot;TermII.6&quot;, &quot;TermI.7&quot;, &quot;TermII.7&quot;, &quot;TermI.8&quot;, &quot;TermII.8&quot;, &quot;TermI.9&quot;, &quot;TermII.9&quot;, &quot;TermI.10&quot;, &quot;TermII.10&quot;) After that, I used the gather() function to get all of my grades in a single column. GradeVN &lt;- GradeVN %&gt;% gather(&quot;TermI.6&quot;, &quot;TermII.6&quot;, &quot;TermI.7&quot;, &quot;TermII.7&quot;, &quot;TermI.8&quot;, &quot;TermII.8&quot;, &quot;TermI.9&quot;, &quot;TermII.9&quot;, &quot;TermI.10&quot;, &quot;TermII.10&quot;, key = &quot;Term&quot;, value = &quot;Grade&quot;) Finally, to make my job easier, I got rid of all of my “S” grades as well as all the missing cells in the final table. GradeVN &lt;- GradeVN %&gt;% filter(Grade != &quot;S&quot;, !is.na(Grade)) GradeVN$Grade &lt;- as.double(GradeVN$Grade) Here’s a look at my final table kable(GradeVN %&gt;% head()) Subject Term Grade Math TermI.6 8.0 Physics TermI.6 6.7 Biology TermI.6 9.8 Vietnamese Literature TermI.6 8.2 History TermI.6 9.9 Geography TermI.6 8.7 6.2.2 Data Exploring First, let’s take a look at the distribution for my grades. Below are the visual and numerical summaries for this distribution: GradeVN %&gt;% ggplot(mapping = aes(Grade)) + geom_histogram(bins = 20, fill = &quot;navy&quot;, color = &quot;lightblue&quot;) kable(favstats(~ Grade, data = GradeVN)) min Q1 median Q3 max mean sd n missing 5.9 8.6 9.3 9.7 10 9.054783 0.8090761 115 0 The distribution of my grades from 6th to 10th is skewed to the left, meaning that I tend to get higher grades during those 5 school years. My average (mean) grade is 9.05, and the grade median is 9.3, meaning that half of my grades are greater than 9.3, and the other half is less than 9.3. The lowest grade I had during that time was 5.9, whereas my highest one was a perfect grade (10). That 5.9 grade can be an outlier to this distribution. 6.2.2.1 Grade Frequency Which grades did I get the most and the least during the period of 6th to 10th grade? We’ll about to find out… kable(GradeVN %&gt;% group_by(Grade) %&gt;% summarise(Frequency = n()) %&gt;% arrange(desc(Frequency)) %&gt;% head()) Grade Frequency 9.9 11 9.4 10 9.7 8 9.3 7 10.0 7 9.1 6 kable(GradeVN %&gt;% group_by(Grade) %&gt;% summarise(Frequency = n()) %&gt;% arrange((Frequency)) %&gt;% head()) Grade Frequency 5.9 1 6.6 1 6.7 1 7.6 1 8.1 1 7.8 2 My most popular grade was 9.9, whereas 9.4 came in second place with just 1 less appearance. All of my top grades were all above 9 (90%), and a perfect score (10.0) also made the top list. On the other hand, there were 5 grades that I only got each one of them once (5.9, 6.6, 6.7, 7.6, 8.1, 7.8). They were all close to 8 or below that. 6.2.2.2 Semester Average To find my average grade for each semester, I first find the cells corresponding to the each one of the term and then take the mean of column “Grade” of those cells. I put everything in a table in a narrow format with 3 variables Grade, Term and Average AverageGrade &lt;- tribble( ~Grade,~Term, ~Average, 6, &quot;I&quot;, mean(GradeVN[1:13,3]$Grade), 6, &quot;II&quot;, mean(GradeVN[14:26,3]$Grade), 7, &quot;I&quot;, mean(GradeVN[27:39,3]$Grade), 7, &quot;II&quot;, mean(GradeVN[39:49,3]$Grade), 8, &quot;I&quot;, mean(GradeVN[50:60,3]$Grade), 8, &quot;II&quot;, mean(GradeVN[61:71,3]$Grade), 9, &quot;I&quot;, mean(GradeVN[72:81,3]$Grade), 9, &quot;II&quot;, mean(GradeVN[82:91,3]$Grade), 10, &quot;I&quot;, mean(GradeVN[92:103,3]$Grade), 10, &quot;II&quot;, mean(GradeVN[104:115,3]$Grade) ) Here’s a look at the table that I just created. kable(AverageGrade) Grade Term Average 6 I 8.838461 6 II 9.338461 7 I 9.200000 7 II 9.372727 8 I 8.781818 8 II 9.318182 9 I 9.550000 9 II 9.280000 10 I 8.458333 10 II 8.591667 I also made a boxplot to compare my grades throughout the semesters: GradeVN %&gt;% ggplot(mapping = aes(x = Term, y = Grade, color = Term)) + geom_boxplot() My highest semester average was Term I of 9th Grade, where I had a 9.6 overall average; whereas the term that I received the lowest grade average was Term I of 10th Grade, where I got an average of 8.5. All of my semester averages were greater than or equal to 8.5, and there were 6 semesters where I had an average above 9. The are some outliers in TermI.8, TermI.9, TermII.8 and TermII.9. 6.2.2.3 Math vs Literature In Vietnam, the 2 most important subject are Math and Vietnamese Literature. So I wanted to look at how well I did in those 2 classes throughout the years. Using my final Grade table, I created a table called “MathLit” by filtering out every subject but Math and Vietnamese Literature. Here’s a look at the first few rows of my new table: MathLit &lt;- GradeVN %&gt;% filter(Subject %in% c(&quot;Math&quot;,&quot;Vietnamese Literature&quot;)) kable(MathLit %&gt;% head()) Subject Term Grade Math TermI.6 8.0 Vietnamese Literature TermI.6 8.2 Math TermII.6 9.7 Vietnamese Literature TermII.6 8.9 Math TermI.7 8.8 Vietnamese Literature TermI.7 8.7 Then I made this graph to compare my Math and Literature Grades MathLit %&gt;% ggplot() + geom_line(mapping = aes(x = Term, y = Grade, group = Subject, color = Subject)) Overall, I had higher grade in Math than Literature in every semester but the first term of 6th grade. My lowest Math grade was an 8.0 in Term I.6; whereas my highest grade for this class is 10.0 in my second semester of 9th grade. For Literature, the 2 semester where I had the lowest grade were term 1 and 2 of 10th grade, where my grades were both slightly less than 7.5. My highest Lit semester grade was TermII.7 where I received a grade slightly above 9. The difference in Math and Lit grades were the greatest in TermI.9 and TermII.9, as my Math grades were about 1.5 points higher than Literature. "],
["part-ii-tennis2017.html", "7 Part II - Tennis2017 7.1 Introduction 7.2 Analysis", " 7 Part II - Tennis2017 7.1 Introduction 7.1.1 Topic . Tennis is one of my 3 favorite sports - alongside with soccer and basketball. I have been following tennis since 2010, and have also witnessed so many great matches over the years. I actually stopped watching it for a little while after my third year, mainly due to the fact that my favorite tennis player - Roger Federer - was dealing with injury back then. But then I started paying attention to tennis again last year (2017), because Federer has made an incredible comeback and played very well. So for all of those reasons, I decided to choose a dataset about men’s tennis in 2017 and make some analysis. 7.1.2 Data I started looking for data, and I was fortunate to find one dataset about tennis matches in 2017 available online. Here’s the link to the online dataset: https://github.com/JeffSackmann/tennis_atp/blob/master/atp_matches_2017.csv . I copied and put everything in a text file (.txt) This dataset consists of 2886 observational units - which are the number of tennis matches in 2017. It has a total of 49 variables which can be divided into the following groups: Tournament: tourney_id, tourney_name, surface, draw_size, tourney_level, tourney_date Match: match_num, best_of (3 or 5), round, minutes Player (winner/loser) information: id, seed, entry, name, hand (L/R), ht (height - in cm), ioc (country code), age, rank, rank_points Player(winner/loser)’s stats: ace, df (double-fault), svpt (service points), 1stIn, 1stWon, 2ndWon (1st/2nd = First/Second serve), svGms (service games), bpSaved, bpFaced (bp = break points) 7.2 Analysis As usual, before making any analysis, the following packages must be loaded. library(tidyverse) library(knitr) library(mosaic) The data file was read in from my personal folder. ATP2017 &lt;- read.csv(&quot;~/Data229/Project/Tennis2017/ATP2017.txt&quot;) 7.2.1 Wins and Losses First, let’s do some simple data transformation to find out who had the most W’s and L’s last year. kable(ATP2017 %&gt;% group_by(winner_name) %&gt;% summarise(Wins = n()) %&gt;% arrange(desc(Wins)) %&gt;% head(8)) winner_name Wins Rafael Nadal 67 David Goffin 59 Alexander Zverev 55 Roger Federer 53 Grigor Dimitrov 49 Roberto Bautista Agut 48 Dominic Thiem 47 Marin Cilic 45 Rafael Nadal - who ended 2017 as the number 1 ranked single tennis player - led the way with 67 wins. We also found out that 4 players had 50+ wins last year: Nadal, D.Goffin, A.Zverev, R.Federer. kable(ATP2017 %&gt;% group_by(loser_name) %&gt;% summarise(losses = n()) %&gt;% arrange(desc(losses)) %&gt;% head(8)) loser_name losses Paolo Lorenzi 35 Joao Sousa 32 Mischa Zverev 32 Albert Ramos 31 Benoit Paire 31 Kyle Edmund 30 Robin Haase 30 Jan Lennard Struff 29 Paolo Lorenzi had the most losses in 2017 with 35 L’s. 7 players got defeated 30 or more times last year. 7.2.2 Match Duration Next, I wanted to analyze the length of 2017 matches. I devided this into 2 separate parts: Best of 3 and Best of 5 7.2.2.1 Best of 3 Matches Best of 3 matches are matches on the ATP (A) and Masters (M) levels. Below are the numerical and visual summaries of the duration (in minutes) of BO3 matches: Bestof3 &lt;- ATP2017 %&gt;% filter(tourney_level == c(&quot;A&quot;, &quot;M&quot;)) kable(favstats(~ minutes, data = Bestof3)) min Q1 median Q3 max mean sd n missing 0 73 92 120 192 97.18857 32.01734 1050 14 Bestof3 %&gt;% filter(!is.na(minutes)) %&gt;% ggplot(mapping = aes(minutes)) + geom_histogram(bins = 25, color = &quot;black&quot;, fill = &quot;tan&quot;) The minute distribution of BO3 matches looks kind of normalish. The mean duration is about 97 minutes (1 hour and 37 minutes). The median duration is 92, which means half of the matches took place for more than 92 minutes and the other half was played in less than an hour and 32 minutes. The minimum time is 0, which means there was a withdrawal before the match started; whereas the maximum time is 192 minutes, meaning the longest Best of 3 match in 2007 lasted for 3 hours and 32 minutes. 7.2.2.2 Best of 5 Matches Best of 3 matches are Grand Slam (G) and Davis Cup (D) matches. Below are the numerical and visual summaries of the duration (in minutes) of BO5 matches: Bestof5 &lt;- ATP2017 %&gt;% filter(tourney_level == c(&quot;G&quot;, &quot;D&quot;)) kable(favstats(~ minutes, data = Bestof5)) min Q1 median Q3 max mean sd n missing 28 109 134 168.25 296 141.4973 49.01037 368 13 Bestof5 %&gt;% filter(!is.na(minutes)) %&gt;% ggplot(mapping = aes(minutes)) + geom_histogram(bins = 25, color = &quot;black&quot;, fill = &quot;orange&quot;) The minutes distribution of BO5 matches also has a normalish shape (and more normal than BO3’s). 141 minutes (2 hours and 21 minutes) is the average match duration. The median time is 134, which means half of the matches lasted longer than 134 minutes and the other half occured in less than 2 hours and 14 minutes. The minimum time is 28, which means the match actually took place and player(s) might have suffered from some sort of injury at the 28-minute mark. On the other hand, the longest match was lasted for 296 minutes (4 hours and 56 minutes) - almost 5 hours long. 7.2.3 Number of Aces vs Height My theory about tennis is that in order to win, you have to serve well. One of the main figures to show how well you serve is the number of aces you have in a match. And so ace is my favorite tennis stat. I also believe that taller players, because of their height advantage, tend to serve better and have more aces than shorter players. So I want to find out if there is any correlation between aces and height. My goal is to have a table in narrow format with 2 variables “ace” and “ht”. So I first selected the 4 variables “w_ace”, “l_ace”, “winner_ht” and “loser_ht” from the original table and then used 2 gather()’s and did some filtering to turn it into a tall table. AcevsHt &lt;- ATP2017 %&gt;% select(w_ace, winner_ht, l_ace, loser_ht) %&gt;% gather(w_ace, l_ace, key = who, value = ace) %&gt;% gather(winner_ht, loser_ht, key = who, value = ht) %&gt;% select(-who) %&gt;% filter(!is.na(ace), !is.na(ht)) Now let’s take a quick look at the table that was just created. kable(AcevsHt %&gt;% head()) ace ht 7 188 4 188 1 178 23 196 3 188 3 178 Below is the ht vs ace plot: AcevsHt %&gt;% ggplot(mapping = aes(x = ace , y = ht)) + geom_point() + stat_smooth(method = &quot;lm&quot;, se = FALSE, size = 2) lm(ht ~ ace, data = AcevsHt) Call: lm(formula = ht ~ ace, data = AcevsHt) Coefficients: (Intercept) ace 184.2134 0.3199 The plot above reveals a positive but weak relationship between aces and height. So we can say that the overall trend is the taller the player is, the more aces he makes. The regression equaiton is ht^ = 0.32*ace. This equation has a slope of 0.32, meaning that every extra ace is associated with 0.32 cm of taller height. 7.2.4 Roger Federer Like I mentioned in my introduction, my favorite tennis player is Roger Federer. So I want to investigate a little bit in his successful 2017 season. 7.2.4.1 Head to Head First, let’s find out who got beaten by Federer the most in 2017. kable(ATP2017 %&gt;% filter(winner_name == &quot;Roger Federer&quot;) %&gt;% group_by(loser_name) %&gt;% summarise(Total_Wins = n()) %&gt;% filter(Total_Wins &gt; 1) %&gt;% arrange(desc(Total_Wins)) %&gt;% head()) loser_name Total_Wins Rafael Nadal 4 Francis Tiafoe 3 Juan Martin Del Potro 3 Mischa Zverev 3 Tomas Berdych 3 Alexander Zverev 2 Surprisingly, Federer defeated his main rival Rafael Nadal 4 times, his most against any opponents in 2017. He also had 3 victories over 4 players (Tiafoe, Del Potro, Zverev and Berdych). 7.2.4.2 Surface Performance Next, let’s look at Federer’s surface performance. Here are the numerical and visual summaries: kable(ATP2017 %&gt;% filter(winner_name == &quot;Roger Federer&quot;) %&gt;% group_by(surface) %&gt;% summarise(Matches = n())) surface Matches Grass 12 Hard 41 ATP2017 %&gt;% filter(winner_name == &quot;Roger Federer&quot;) %&gt;% group_by(surface) %&gt;% summarise(Matches = n()) %&gt;% ggplot(mapping = aes(x = &quot;&quot;, y = Matches, fill = surface)) + geom_bar(stat = &quot;identity&quot;) + coord_polar(&quot;y&quot;, start = 0) + scale_fill_brewer(palette =&quot;Accent&quot;) + theme_minimal() + xlab(&quot;&quot;) + ylab(&quot;&quot;) In 2017, Federer won 41 matches on hard courts and 12 matches on grass courts. These 2 are his favorite surfaces. One more thing we need to notice is that Federer didn’t have any wins on clay, due to the fact that he skipped the entire clay-court season. 7.2.4.3 Aces As I mentioned in the previous part, my favorite tennis stat is number of aces. Roger Federer is a great server and is number 2 on the career aces list. So I wanted to find out about Federer’s aces in 2017. The first thing I did was creating a table in the narrow format with only 2 variables Ace and Player, and then got rid of every name but Roger Federer. FedAce &lt;- ATP2017 %&gt;% select(winner_name, loser_name, w_ace, l_ace) %&gt;% gather(w_ace, l_ace, key = who, value = ace) %&gt;% gather(winner_name, loser_name, key = who, value = Player) %&gt;% select(-who) %&gt;% filter(Player == &quot;Roger Federer&quot;) kable(FedAce %&gt;% head()) ace Player 19 Roger Federer 17 Roger Federer 8 Roger Federer 24 Roger Federer 9 Roger Federer 11 Roger Federer Now I had my table, and it’s time to check out the distribution of Federer’s 2017 aces. FedAce %&gt;% ggplot(mapping = aes(ace)) + geom_histogram(bins = 25, color = &quot;black&quot;, fill = &quot;grey&quot;) kable(favstats(~ ace, data = FedAce)) min Q1 median Q3 max mean sd n missing 0 4 6.5 11 24 7.596491 4.807294 114 2 The shape of Federer’s 2017 aces distribution is skewed to the right. His average number of aces last year were 7.6, so about 8 aces per match. His highest number of aces in one match was 24. There were some matches that Federer did not have a single ace, that’s why the minimum aces in 0. "]
]
